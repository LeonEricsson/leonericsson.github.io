---
layout: post
title: "Andrej Karpathy: Tesla AI, Self-Driving, Optimus, Aliens, and AGI | Lex Fridman"
categories: [Deep Learning, Data Science]
year: 2022
type: podcast
author: Lex Fridman
exturl: https://www.youtube.com/watch?v=cdiD-9MMpb0&ab_channel=LexFridman
---

Very informative talk from the former head of AI at Tesla, founding member of OpenAI. Key takeaways from the talk:
- AI areas such as Computer Vision, Speech Recognition, Audio have formerly had separate optimal architectures but during the past 5 years there has been a convergence towards the Transformer. 
- Large language models like GPT-3 are very interesting as it seems they transcend the area of just language modeling at least somewhat into the space of AGI in the sense that they create an understanding of things like Chemistry, Physics etc. In the task of predicting the 1001th word in a sequence over the entire data set you need to understand the context very very well. With powerful architectures like the transformer there is actually a lot of in-context learning going on. 
- Around 2015 the community was very focused around RL and training NN from scratch using RL (Mnih et al, AlphaGo, Dota etc) but this approach was found to be very inefficient. Training NN from scratch using RL takes way too long, you have to wait until a reward is observed then update the network and it’s just too inefficient. 
- We’re moving towards a world where we share the digital space with AI (and ultimately the physical space). It’s going to be an arms race to detect malicious sentient systems online. AI forming connections to humans through text is very likely, a lot of our data online is based around feelings, connections, and emotion hence systems built like GPT-3 have a very good contextual understanding of human interaction. 
- Neural Networks are gradually replacing software we previously believed needed to be programmed by hand. Formerly we thought image features needed to be handcrafted with a neural network running the classifier, this is now completely done by NN. When fusing multiple cameras we thought NN would run individually and then software would fuse them together, now everything is fed to a NN architecture that does the fusion itself.
- Datasets need to be expansive, clean and diverse. It’s the most important part of machine learning. Tesla’s Data Engine is a great example for achieving this, they start with some dataset, train, deploy it in the live system and monitor it live to detect areas which the NN finds difficult then it uses that data to update the dataset in an iterative staircase manner. 



