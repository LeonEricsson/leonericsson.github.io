---
layout: post
title: "Mistral 7B"
categories: [NLP]
year: 2023
type: paper
author: Jiang
exturl: https://arxiv.org/pdf/2310.06825.pdf
---

Whisper trained on raw text of transcripts without any significant standardization, relying on the expressiveness of sequence to sequence models to learn to map between speech and their transcribed form.

## Data
Data curation process was immensely important.

The dataset consist of audio $a_i$ paired with transcriptions $t_i$ from the internet, ($a_i$, $t_i$). This obviously results in a very diverse dataset, from different environments, recording setups, speakers, and languages. Diversity in audio quality is great! But diversity in transcript quality is not similarly beneficial because it interferes with the learning reward signal. 

The data transcripts, while abundant, are usually not human-generated but rather a result of existing automated speech recognition systems. This is a problem because research has shown that training on datasets of mixed human and machine genereated data can impair the performance of translation systems.

The team developed a number of heuristics in order to curate the dataset and remove such automated transcripts, leaving only human transcribed data. This is possible because a lot of ASR systems don't produce proper whitespace, stylistics such as punctuation. This means many can be detected with simple or rule-based systems.

Audio is broken inte files of 30-seconds, paired with the subset of the transcript that occurs with that time segment. 

A very smart filtering method was that they trained an initial model, aggregared information about its error rate on the training data sources and performed manual inspection of the data points the model struggled with. This inspection found a large amount of low-quality e.g. partially transcribed, poorly aligned or machine-generated transcriptions that the filtering heursistics missed.


